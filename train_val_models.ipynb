{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0XlFZN6ymUk"
   },
   "source": [
    "# **Demo Overview: UNet-Based Bamboo Segmentation**\n",
    "\n",
    "This demo demonstrates how to train UNet-based semantic segmentation models for bamboo mapping using remote sensing imagery.\n",
    "The supported input data sources include:\n",
    "\n",
    "- RGB imagery\n",
    "\n",
    "- Canopy Height Model (CHM)\n",
    "\n",
    "- Fusion of RGB and CHM data\n",
    "\n",
    "The demo focuses on image-based segmentation workflows and does not directly process raw point cloud data.\n",
    "\n",
    "\n",
    "#### Contact Information\n",
    "\n",
    "Prof. Chinsu Lin: chinsu@mail.ncyu.edu.tw\n",
    "\n",
    "Prof. Wenzhi Liao: wenzhi.liao@ugent.be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Clyi1b4V6j_B"
   },
   "source": [
    "# Model training with your annotated images\n",
    "\n",
    "### STEP1: configure the path of image, masks and save_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "T8yLEEw1uHyJ"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "#import wandb\n",
    "from utils.evaluate import evaluate\n",
    "from unet import UNet\n",
    "from utils.data_loading import BasicDataset\n",
    "from utils.dice_score import dice_loss\n",
    "\n",
    "\n",
    "def train_model(\n",
    "        model,\n",
    "        device,\n",
    "        epochs: int = 5,\n",
    "        batch_size: int = 1,\n",
    "        learning_rate: float = 1e-5,\n",
    "        val_percent: float = 0.1,\n",
    "        save_checkpoint: bool = True,\n",
    "        img_scale: float = 0.5,\n",
    "        amp: bool = False,\n",
    "        weight_decay: float = 1e-8,\n",
    "        momentum: float = 0.999,\n",
    "        gradient_clipping: float = 1.0,\n",
    "):\n",
    "    # 1. Create dataset\n",
    "    dataset = BasicDataset(dir_img, dir_mask, img_scale)\n",
    "\n",
    "    # 2. Split into train / validation partitions\n",
    "    n_val = int(len(dataset) * val_percent)\n",
    "    n_train = len(dataset) - n_val\n",
    "    train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "    # 3. Create data loaders\n",
    "    loader_args = dict(batch_size=batch_size, num_workers=os.cpu_count(), pin_memory=True)\n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "\n",
    "    # 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "    optimizer = optim.RMSprop(model.parameters(),\n",
    "                              lr=learning_rate, weight_decay=weight_decay, momentum=momentum, foreach=True)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5)  # goal: maximize Dice score\n",
    "    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "    criterion = nn.CrossEntropyLoss() if model.n_classes > 1 else nn.BCEWithLogitsLoss()\n",
    "    global_step = 0\n",
    "\n",
    "    # 5. Begin training\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                images, true_masks = batch['image'], batch['mask']\n",
    "\n",
    "                assert images.shape[1] == model.n_channels, \\\n",
    "                    f'Network has been defined with {model.n_channels} input channels, ' \\\n",
    "                    f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n",
    "                    'the images are loaded correctly.'\n",
    "\n",
    "                images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "                true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "\n",
    "                with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n",
    "                    masks_pred = model(images)\n",
    "                    if model.n_classes == 1:\n",
    "                        loss = criterion(masks_pred.squeeze(1), true_masks.float())\n",
    "                        loss += dice_loss(F.sigmoid(masks_pred.squeeze(1)), true_masks.float(), multiclass=False)\n",
    "                    else:\n",
    "                        loss = criterion(masks_pred, true_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float(),\n",
    "                            F.one_hot(true_masks, model.n_classes).permute(0, 3, 1, 2).float(),\n",
    "                            multiclass=True\n",
    "                        )\n",
    "\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                grad_scaler.scale(loss).backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "\n",
    "                pbar.update(images.shape[0])\n",
    "                global_step += 1\n",
    "                epoch_loss += loss.item()\n",
    "                print(f\"loss: {loss.item()}\")\n",
    "                # Evaluation round\n",
    "                division_step = (n_train // (5 * batch_size))\n",
    "                if division_step > 0:\n",
    "                    if global_step % division_step == 0:\n",
    "                        histograms = {}\n",
    "                        for tag, value in model.named_parameters():\n",
    "                            tag = tag.replace('/', '.')\n",
    "\n",
    "                        val_score = evaluate(model, val_loader, device, amp)\n",
    "                        scheduler.step(val_score)\n",
    "\n",
    "        # Save checkpoint every 10 epochs\n",
    "        if (save_checkpoint)&(epoch % save_interval == 0):\n",
    "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "            state_dict = model.state_dict()\n",
    "            state_dict['mask_values'] = dataset.mask_values\n",
    "            torch.save(state_dict, str(dir_checkpoint / 'checkpoint_epoch{}.pth'.format(epoch)))\n",
    "            logging.info(f'Checkpoint {epoch} saved!')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChKYB5Kt0eP2"
   },
   "source": [
    "## configure the data root for model training\n",
    "Change here to adapt to your data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'RGB'\n",
    "# mode = 'CHM'\n",
    "# mode = 'Fusion'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:17<00:00,  3.79it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from skimage.io import imread,imsave, imshow\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # often cleaner\n",
    "\n",
    "# =========================\n",
    "# CONFIG data root\n",
    "# =========================\n",
    "dir_RGB = Path('./data/annotations/train/RGB/')\n",
    "dir_CHM = Path('./data/annotations/train/CHM/')\n",
    "dir_mask = Path('./data/annotations/train/masks/')\n",
    "\n",
    "if mode == \"RGB\":\n",
    "    dir_img = dir_RGB\n",
    "    n_channels=3 \n",
    "elif mode == \"CHM\":\n",
    "    dir_img = dir_CHM\n",
    "    n_channels=1\n",
    "\n",
    "else:\n",
    "    dir_img = Path('./data/annotations/train/fusion/')\n",
    "    n_channels=4\n",
    "    os.makedirs(dir_img, exist_ok=True)\n",
    "    # ---------------- MAIN ----------------\n",
    "    rgb_files = sorted(os.listdir(dir_RGB))\n",
    "    \n",
    "    for fname in tqdm(rgb_files):\n",
    "        base, _ = os.path.splitext(fname)\n",
    "    \n",
    "        rgb_path = os.path.join(dir_RGB, fname)\n",
    "        chm_path = os.path.join(dir_CHM, base + \".tif\")\n",
    "    \n",
    "        if not os.path.exists(chm_path):\n",
    "            print(f\"[WARNING] Missing CHM for {fname}\")\n",
    "            continue\n",
    "    \n",
    "        # --- Read RGB ---\n",
    "        rgb = imread(rgb_path)\n",
    "        if rgb is None:\n",
    "            continue\n",
    "    \n",
    "        # --- Read CHM ---\n",
    "        chm = imread(chm_path)\n",
    "        chm = np.uint8(255*chm/chm.max())\n",
    "    \n",
    "        # --- Stack ---\n",
    "        fused = np.dstack([rgb, chm])  # (H, W, 4)\n",
    "    \n",
    "        imsave(os.path.join(dir_img, base + \".png\"), fused.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configure the parameter for model training\n",
    "Change here to adapt to your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "p_6SpbTfyi15"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using device cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Number of classes you define\n",
    "classes = 2\n",
    "\n",
    "save_interval = 20\n",
    "\n",
    "bilinear=False\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "learning_rate=1e-5\n",
    "\n",
    "# # Downscaling factor of the images\n",
    "scale =0.5\n",
    "\n",
    "## Percent of the data that is used as validation (0-100)\n",
    "Val_percent =10.0\n",
    "\n",
    "## 'store_true', default=False, help='Use mixed precision'\n",
    "amp = False\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info(f'Using device {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvV9cYh30u9x"
   },
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "error",
     "timestamp": 1741018614789,
     "user": {
      "displayName": "Wenzhi Liao",
      "userId": "03545043954170273172"
     },
     "user_tz": -60
    },
    "id": "Smy2u3f8uZBE",
    "outputId": "c327c61a-df3c-4a93-dc77-89afeb602480"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Creating dataset with 66 examples\n",
      "INFO: Scanning mask files to determine unique values\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:05<00:00, 11.47it/s]\n",
      "INFO: Unique mask values: [0, 255]\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_36516\\3451840207.py:53: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
      "Epoch 1/100:   7%|████▌                                                                | 4/60 [00:17<04:06,  4.41s/img]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.2569853067398071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:  13%|█████████▏                                                           | 8/60 [00:21<02:06,  2.43s/img]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.017229437828064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:  20%|█████████████▌                                                      | 12/60 [00:27<01:37,  2.03s/img]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.9501457810401917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation round:   0%|                                                                       | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.78s/batch]\u001b[A\n",
      "Epoch 1/100:  33%|██████████████████████▋                                             | 20/60 [00:44<01:19,  1.98s/img]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8376666903495789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:  40%|███████████████████████████▏                                        | 24/60 [00:50<01:05,  1.81s/img]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6627688407897949\n",
      "loss: 0.7410179972648621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation round:   0%|                                                                       | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.51s/batch]\u001b[A\n",
      "Epoch 1/100:  47%|███████████████████████████████▋                                    | 28/60 [01:06<01:22,  2.58s/img]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8135425448417664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:  53%|████████████████████████████████████▎                               | 32/60 [01:14<01:06,  2.37s/img]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7989020347595215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:  60%|████████████████████████████████████████▊                           | 36/60 [01:20<00:50,  2.10s/img]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.40488237142562866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation round:   0%|                                                                       | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.77s/batch]\u001b[A\n",
      "Epoch 1/100:  67%|█████████████████████████████████████████████▎                      | 40/60 [01:28<00:40,  2.03s/img]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.892285168170929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:  73%|█████████████████████████████████████████████████▊                  | 44/60 [01:34<00:30,  1.89s/img]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6520134210586548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:  80%|██████████████████████████████████████████████████████▍             | 48/60 [01:39<00:20,  1.73s/img]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6133875250816345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation round:   0%|                                                                       | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.81s/batch]\u001b[A\n",
      "Epoch 1/100:  87%|██████████████████████████████████████████████████████████▉         | 52/60 [01:57<00:20,  2.53s/img]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.221940279006958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:  93%|███████████████████████████████████████████████████████████████▍    | 56/60 [02:04<00:09,  2.30s/img]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5060531497001648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|████████████████████████████████████████████████████████████████████| 60/60 [02:05<00:00,  1.68s/img]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4971362054347992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation round:   0%|                                                                       | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.05s/batch]\u001b[A\n",
      "Epoch 1/100: 100%|████████████████████████████████████████████████████████████████████| 60/60 [02:18<00:00,  2.30s/img]\u001b[A\n",
      "Epoch 2/100:   7%|████▌                                                                | 4/60 [00:11<02:37,  2.81s/img]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7722710967063904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100:  13%|█████████▏                                                           | 8/60 [00:18<01:58,  2.29s/img]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5489740371704102\n",
      "loss: 0.3741442561149597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation round:   0%|                                                                       | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.62s/batch]\u001b[A\n",
      "Epoch 2/100:  27%|██████████████████▏                                                 | 16/60 [00:31<01:22,  1.88s/img]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.49815839529037476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100:  33%|██████████████████████▋                                             | 20/60 [00:43<01:27,  2.19s/img]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5703669190406799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100:  40%|███████████████████████████▏                                        | 24/60 [00:49<01:11,  1.98s/img]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7612590789794922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation round:   0%|                                                                       | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.70s/batch]\u001b[A\n",
      "Epoch 2/100:  53%|████████████████████████████████████▎                               | 32/60 [01:03<00:48,  1.72s/img]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6227600574493408\n"
     ]
    }
   ],
   "source": [
    "model = UNet(n_channels=n_channels, n_classes = classes, bilinear=bilinear)\n",
    "model = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "\n",
    "model.to(device=device)\n",
    "train_model(\n",
    "    model=model,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    device=device,\n",
    "    img_scale=scale,\n",
    "    val_percent=Val_percent / 100,\n",
    "    amp=amp\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing and Evaluation\n",
    "\n",
    "After training, the UNet models can be tested using the trained weights to evaluate their performance on unseen data.\n",
    "\n",
    "During testing, the models can be evaluated using different input data sources:\n",
    "\n",
    "- RGB imagery\n",
    "\n",
    "- Canopy Height Model (CHM)\n",
    "\n",
    "- Fused RGB–CHM inputs\n",
    "\n",
    "The trained models are applied to the test dataset to generate bamboo segmentation maps, which can then be assessed using standard segmentation metrics or visual inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vqrQh-TlRK4u"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils.data_loading import BasicDataset\n",
    "from unet import UNet\n",
    "from skimage.io import imread,imsave, imshow\n",
    "def predict_img(net,\n",
    "                full_img,\n",
    "                device,\n",
    "                scale_factor=1,\n",
    "                out_threshold=0.5):\n",
    "    net.eval()\n",
    "    img = torch.from_numpy(BasicDataset.preprocess(None, full_img, scale_factor, is_mask=False))\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.to(device=device, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = net(img).cpu()\n",
    "        output = F.interpolate(output, (full_img.size[1], full_img.size[0]), mode='bilinear')\n",
    "        if net.n_classes > 1:\n",
    "            mask = output.argmax(dim=1)\n",
    "        else:\n",
    "            mask = torch.sigmoid(output) > out_threshold\n",
    "\n",
    "    return mask[0].long().squeeze().numpy()\n",
    "\n",
    "def compute_iou(pred, target, num_classes):\n",
    "    \"\"\"\n",
    "    Compute Mean IoU for a single image.\n",
    "\n",
    "    Args:\n",
    "        pred (torch.Tensor): Model predictions (H, W) - class indices.\n",
    "        target (torch.Tensor): Ground truth labels (H, W) - class indices.\n",
    "        num_classes (int): Number of classes.\n",
    "\n",
    "    Returns:\n",
    "        float: Mean IoU score.\n",
    "    \"\"\"\n",
    "    ious = []\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = (pred == cls)\n",
    "        target_inds = (target == cls)\n",
    "\n",
    "        intersection = (pred_inds & target_inds).sum().item()\n",
    "        union = (pred_inds | target_inds).sum().item()\n",
    "\n",
    "        if union == 0:\n",
    "            iou = float('nan')  # Ignore class if it does not appear\n",
    "        else:\n",
    "            iou = intersection / union\n",
    "        ious.append(iou)\n",
    "\n",
    "    # Remove NaN values and compute mean IoU\n",
    "    ious = [iou for iou in ious if not isinstance(iou, float) or not torch.isnan(torch.tensor(iou))]\n",
    "    return sum(ious) / len(ious) if ious else 0.0\n",
    "\n",
    "\n",
    "\n",
    "def overlay_mask_on_image(image, mask, color=(0, 0, 255), alpha=0.3):\n",
    "    \"\"\"\n",
    "    Overlay a mask onto an image with a given color and transparency.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "        mask_path (str): Path to the segmentation mask image.\n",
    "        output_path (str): Path to save the output image with overlay.\n",
    "        color (tuple): BGR color for the mask overlay (default red: (0, 0, 255)).\n",
    "        alpha (float): Transparency factor for the overlay (0: fully transparent, 1: fully opaque).\n",
    "    \"\"\"\n",
    "    # Create a colored version of the mask\n",
    "    colored_mask = np.zeros_like(image)\n",
    "    colored_mask[:] = color\n",
    "\n",
    "    # Create a binary mask: True where mask > 0\n",
    "    binary_mask = mask > 0\n",
    "\n",
    "    # Make a copy of the original image for the overlay\n",
    "    overlayed_image = image.copy()\n",
    "\n",
    "    # Blend the colored mask with the image where the mask is present\n",
    "    overlayed_image[binary_mask] = cv2.addWeighted(image[binary_mask], 1 - alpha,\n",
    "                                                    colored_mask[binary_mask], alpha, 0)\n",
    "\n",
    "    # Save the result\n",
    "    return overlayed_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 585,
     "status": "ok",
     "timestamp": 1741018928596,
     "user": {
      "displayName": "Wenzhi Liao",
      "userId": "03545043954170273172"
     },
     "user_tz": -60
    },
    "id": "gflY66c3EqrZ",
    "outputId": "398b2685-440c-4b47-d7fc-b56269733717"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = UNet(n_channels=n_channels, n_classes=classes, bilinear=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net.to(device=device)\n",
    "# state_dict = torch.load('checkpoints/checkpoint_epoch100.pth', map_location=device)\n",
    "state_dict = torch.load('models/model_RGB_2annotation.pth', map_location=device)\n",
    "\n",
    "mask_values = state_dict.pop('mask_values', [0, 1])\n",
    "net.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the IoU for all test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DJvgl0bBaQHN"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# dir_img = Path(\"data/annotations/test/RGB\")\n",
    "image_files = [\n",
    "    f for f in os.listdir(\"data/annotations/test/RGB\") #os.listdir(dir_img)#i\n",
    "    if f.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "executionInfo": {
     "elapsed": 994,
     "status": "error",
     "timestamp": 1740641575378,
     "user": {
      "displayName": "Wenzhi Liao",
      "userId": "03545043954170273172"
     },
     "user_tz": -480
    },
    "id": "rzdleQsMQlVS",
    "outputId": "ee055d00-2ea5-404b-8aa9-ad91fc654f0b"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "dir_results = 'results/'\n",
    "os.makedirs(dir_results, exist_ok=True)\n",
    "for im in image_files:\n",
    "\n",
    "    patch_img = Image.open('data/annotations/test/RGB/' + im)\n",
    "    targets = imread('data/annotations/test/masks/' + im)\n",
    "    preds = predict_img(net=net,\n",
    "                full_img=patch_img,\n",
    "                scale_factor=0.5,\n",
    "                out_threshold=0.5,\n",
    "                device=device)\n",
    "\n",
    "    imsave(dir_results + im, np.uint8(255*preds))\n",
    "\n",
    "\n",
    "    # Compute mIoU\n",
    "    mIoU = compute_iou(preds*255, targets, num_classes=2)\n",
    "    results.append(mIoU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7qgw3S0yS9Co"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'image':image_files, 'IoU':results})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lWXmes_tXdyl"
   },
   "outputs": [],
   "source": [
    "df.to_csv('results/CHM_accuracy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1740634164058,
     "user": {
      "displayName": "Wenzhi Liao",
      "userId": "03545043954170273172"
     },
     "user_tz": -480
    },
    "id": "wtCItzRFX6Kd",
    "outputId": "80fdf313-c0cf-4f74-8a85-01fdeaee52c5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>IoU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patch_H10240_W5120.png</td>\n",
       "      <td>0.616298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patch_H1024_W12288.png</td>\n",
       "      <td>0.900983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patch_H15360_W2048.png</td>\n",
       "      <td>0.798089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patch_H15360_W5120.png</td>\n",
       "      <td>0.802158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>patch_H15360_W9216.png</td>\n",
       "      <td>0.735698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>patch_H17408_W12288.png</td>\n",
       "      <td>0.880418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>patch_H19456_W6144.png</td>\n",
       "      <td>0.870943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>patch_H2048_W12288.png</td>\n",
       "      <td>0.878550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>patch_H4096_W14336.png</td>\n",
       "      <td>0.975931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>patch_H5120_W3072.png</td>\n",
       "      <td>0.835870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     image       IoU\n",
       "0   patch_H10240_W5120.png  0.616298\n",
       "1   patch_H1024_W12288.png  0.900983\n",
       "2   patch_H15360_W2048.png  0.798089\n",
       "3   patch_H15360_W5120.png  0.802158\n",
       "4   patch_H15360_W9216.png  0.735698\n",
       "5  patch_H17408_W12288.png  0.880418\n",
       "6   patch_H19456_W6144.png  0.870943\n",
       "7   patch_H2048_W12288.png  0.878550\n",
       "8   patch_H4096_W14336.png  0.975931\n",
       "9    patch_H5120_W3072.png  0.835870"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1740575516112,
     "user": {
      "displayName": "Wenzhi Liao",
      "userId": "03545043954170273172"
     },
     "user_tz": -60
    },
    "id": "_hIvHFfoTFVA",
    "outputId": "0e94bb54-4cf9-441f-e5ee-7a502c10fe8b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-80-fedb3903422a>:1: FutureWarning: `imshow` is deprecated since version 0.25 and will be removed in version 0.27. Please use `matplotlib`, `napari`, etc. to visualize images.\n",
      "  imshow(preds)\n",
      "/usr/local/lib/python3.11/dist-packages/skimage/io/_plugins/matplotlib_plugin.py:158: UserWarning: Low image data range; displaying image with stretched contrast.\n",
      "  lo, hi, cmap = _get_display_range(image)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7b04050d86d0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(preds)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
